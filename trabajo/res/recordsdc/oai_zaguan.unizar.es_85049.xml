<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/">
    <dc:contributor>Orrite Uruñuela, Carlos Miguel</dc:contributor>
    <dc:creator>Berriel Martins, Tomás</dc:creator>
    <dc:date>2019</dc:date>
    <dc:description>El objetivo de este trabajo es determinar las articulaciones más relevantes para el&lt;br /&gt;análisis de cada clase de acciones, así como diseñar un clasificador de acciones humanas&lt;br /&gt;a partir de la información de un sensor de posición 3D (Kinect). Se parte del análisis&lt;br /&gt;de la base de datos, y continua con el estudio de los parámetros de una red Long Short&lt;br /&gt;Term Memory y el desarrollo de tres clasificadores distintos basados en dichas redes&lt;br /&gt;LSTM.&lt;br /&gt;&lt;br /&gt;</dc:description>
    <dc:identifier>http://zaguan.unizar.es/record/85049</dc:identifier>
    <dc:language>spa</dc:language>
    <dc:publisher>Universidad de Zaragoza; Departamento de Ingeniería Electrónica y Comunicaciones; Área de Tecnología Electrónica</dc:publisher>
    <dc:relation>http://zaguan.unizar.es/record/85049/files/TAZ-TFG-2019-3377.pdf</dc:relation>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
    <dc:subject>Graduado en Ingeniería Electrónica y Automática</dc:subject>
    <dc:title>Reconocimiento automático de acciones humanas en secuencias de vídeo con cámara 3D</dc:title>
    <dc:type>TAZ-TFG</dc:type>
    <dc:title xml:lang="en">Automated human actions recognition in 3D video sequences</dc:title>
</oai_dc:dc>
