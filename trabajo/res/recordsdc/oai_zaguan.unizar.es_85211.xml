<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/">
    <dc:contributor>Murillo Arnal, Ana Cristina</dc:contributor>
    <dc:creator>Salvo Ibáñez, Pilar</dc:creator>
    <dc:date>2019</dc:date>
    <dc:description>En la actualidad encontramos sistemas embebidos en todas partes, en el sistema de frenos ABS, en un proceso de montaje o producción, en los hospitales en equipos de medicina, incluso en radares y en cámaras de vı́deo. Un sistema embebido es un sistema electrónico computacional cuyo hardware y software están diseñados para realizar una o varias funciones especı́ficas, en vez de ocuparse de varias tareas generales a la vez, centradas en llevar a cabo de forma eficiente la aplicación final para la que fue creado.&lt;br /&gt;El objetivo de este proyecto es realizar un estudio de algoritmos de deep learning para un reconocimiento visual eficiente para sistemas de vigilancia y monitorización. La idea es que puedan funcionar en tarjetas gráficas especı́ficas para dispositivos embebidos, buscando conseguir que desde un hardware embebido se sea capaz de detectar objetos de interés, como pueden ser principalmente personas y distintos tipos de vehı́culos.&lt;br /&gt;En el arranque del proyecto se ha seleccionado el algoritmo de YOLO, el cual es destacado por su rapidez en la detección de objetos tanto en imágenes&lt;br /&gt;como en vı́deos a tiempo real. Se ha estudiado el funcionamiento de este, y se ha realizado la adaptación del modelo para los datos y las clases elegidas. En cuanto a los datos a utilizar para entrenar el modelo, se ha seleccionado el dataset público VIRAT. Este contiene 29 horas de vı́deos de vigilancia, en las que se muestran escenas reales de la calle con distintos eventos de personas y vehı́culos.&lt;br /&gt;Al ser vı́deos de cámaras de vigilancia reales, la visualización de las imágenes no es frontal como suele ocurrir en la mayorı́a de los dataset, sino que tiene un enfoque elevado que se busca para que el modelo funcione de manera correcta en cualquier tipo de sistema de seguridad, desde cámaras en los edificios a cámaras llevadas por drones. Las clases en las que se llevara a cabo la detección de objetos en estos vı́deos son cinco: personas, coches, bicicletas, vehı́culos y objetos.&lt;br /&gt;Se han realizado varias pruebas entrenando distintos modelos de YOLO v3, utilizando distintos conjuntos de entrenamiento. Se ha evaluado cada modelo respecto a su precisión en la detección de las distintas clases y se observa que en las clases de personas y coches el modelo propuesto obtiene una detección mejor, mientras que los elementos más pequeños como objetos y bicicletas los reconoce peor. Además, se ha analizado el tiempo de ejecución y el consumo al evaluar una imagen con el modelo creado.&lt;br /&gt;Por último, el modelo que mejor rendimiento obtiene se ha instalado en el dispositivo embebido elegido, la Nvidia Jetson AGX Xavier. Esta plataforma, con su diseño embebido y su consumo eficiente, resulta muy competente para implementar algoritmos de deep learning en sistemas embebidos como el prototipo de vigilancia que se ha construido en este proyecto. Con este prototipo se han realizado pruebas en vivo adicionales donde se ha observado el buen funcionamiento en escenarios reales alrededor del Instituto de Ingenierı́a e Investigación de Aragón.&lt;br /&gt;&lt;br /&gt;</dc:description>
    <dc:identifier>http://zaguan.unizar.es/record/85211</dc:identifier>
    <dc:language>spa</dc:language>
    <dc:publisher>Universidad de Zaragoza; Departamento de Informática e Ingeniería de Sistemas; Área de Ingeniería de Sistemas y Automática</dc:publisher>
    <dc:relation>http://zaguan.unizar.es/record/85211/files/TAZ-TFG-2019-2920.pdf</dc:relation>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
    <dc:subject>Graduado en Ingeniería Electrónica y Automática</dc:subject>
    <dc:title>Sistemas de aprendizaje automático eficientes para reconocimiento visual en sistemas embebidos</dc:title>
    <dc:type>TAZ-TFG</dc:type>
    <dc:title xml:lang="en">Efficient machine learning systems for visual recognition in embedded systems</dc:title>
</oai_dc:dc>
