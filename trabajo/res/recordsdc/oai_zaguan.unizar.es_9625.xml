<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/">
    <dc:contributor>Gutiérrez Pérez, Diego</dc:contributor>
    <dc:contributor>Serón Arbeloa, Francisco José</dc:contributor>
    <dc:creator>Navarro Gil, Fernando</dc:creator>
    <dc:date>2012</dc:date>
    <dc:description>Realistic rendering in computer graphics simulates the interactions of light and surfaces. While many accurate models for surface reflection and lighting, including solid surfaces and participating media have been described; most of them rely on intensive computation. Common practices such as adding constraints and assumptions can increase performance. However, they may compromise the quality of the resulting images or the variety of phenomena that can be accurately represented. In this thesis, we will focus on rendering methods that require high amounts of computational resources. Our intention is to consider several conceptually different approaches capable of reducing these requirements with only limited implications in the quality of the results. The first part of this work will study rendering of time-­¿varying participating media. Examples of this type of matter are smoke, optically thick gases and any material that, unlike the vacuum, scatters and absorbs the light that travels through it. We will focus on a subset of algorithms that approximate realistic illumination using images of real world scenes. Starting from the traditional ray marching algorithm, we will suggest and implement different optimizations that will allow performing the computation at interactive frame rates. This thesis will also analyze two different aspects of the generation of anti-­¿aliased images. One targeted to the rendering of screen-­¿space anti-­¿aliased images and the reduction of the artifacts generated in rasterized lines and edges. We expect to describe an implementation that, working as a post process, it is efficient enough to be added to existing rendering pipelines with reduced performance impact. A third method will take advantage of the limitations of the human visual system (HVS) to reduce the resources required to render temporally antialiased images. While film and digital cameras naturally produce motion blur, rendering pipelines need to explicitly simulate it. This process is known to be one of the most important burdens for every rendering pipeline. Motivated by this, we plan to run a series of psychophysical experiments targeted at identifying groups of motion-­¿blurred images that are perceptually equivalent. A possible outcome is the proposal of criteria that may lead to reductions of the rendering budgets.</dc:description>
    <dc:identifier>http://zaguan.unizar.es/record/9625</dc:identifier>
    <dc:language>spa</dc:language>
    <dc:publisher>Universidad de Zaragoza; Departamento de Informática e Ingeniería de Sistemas</dc:publisher>
    <dc:relation>http://zaguan.unizar.es/record/9625/files/TESIS-2012-112.pdf</dc:relation>
    <dc:rights>https://creativecommons.org/licenses/by-nc-nd/3.0/</dc:rights>
    <dc:subject>tratamiento digital de imágenes</dc:subject>
    <dc:subject>terminales dispositivos gráficos y trazadores</dc:subject>
    <dc:subject>sistemas en tiempo real</dc:subject>
    <dc:title>Optimization techniques for computationally expensive rendering algorithms</dc:title>
    <dc:type>TESIS</dc:type>
</oai_dc:dc>
