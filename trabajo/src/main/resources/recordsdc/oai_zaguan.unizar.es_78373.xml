<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/">
    <dc:contributor>Guerrero Campo, José Jesús</dc:contributor>
    <dc:creator>Guerrero Viu, Manuel</dc:creator>
    <dc:date>2019</dc:date>
    <dc:description>El objetivo principal de este trabajo es el desarrollo de un sistema de detección del espacio libre en una escena que ayude en la planificación de trayectorias para el guiado de personas y que pueda servir como complemento a personas con discapacidad visual. En particular, en este proyecto se estudia el problema de detectar e identificar el plano del suelo para poder avanzar por las zonas libres de obstáculos, así como la expansión del mismo para permitir la planificación de movimientos durante la navegación. Para realizar estas tareas se hace uso de información de rango y de color.  El uso de cámaras RGB-D permite adquirir este tipo de información, sin embargo, su limitado campo de vista y su rango de distancias impide obtener información más completa de la escena. Para solventar este problema, se propone una combinación de sensores a través de una cámara de profundidad que proporciona observaciones seguras delante de la persona, y de una cámara de color con gran campo de vista que permite recuperar información adicional significativa de la escena. La configuración propuesta se inspira en la visión humana donde la parte central de la retina (fóvea) proporciona información más rica que la periferia y a la vez permite un campo de vista amplio. Para ello se utilizan técnicas de procesamiento de información 3D, y de imagen de color, a diferencia de otros sistemas de navegación recogidos en el estado del arte. La clave del proyecto reside en cómo aprovechar e integrar la información procedente de ambos sensores para conseguir la mayor expansión posible y la detección de elementos de interés, favoreciendo la planificación de la trayectoria a seguir por el usuario durante la navegación. Este Trabajo de Fin de Máster se enfoca en cuatro actividades principales: - Realizar una correcta calibración entre ambas cámaras utilizando un novedoso sistema basado en correspondencias de líneas. - Desarrollar un sistema que permita segmentar el suelo de la escena visible combinando la información de la cámara de profundidad y de la cámara fisheye, ampliando de forma notable el campo de vista y el alcance de la cámara de profundidad. - Propuesta de ayuda a la navegación para la transmisión al usuario del espacio libre en la escena.   - Evaluación experimental de las técnicas desarrolladas, en escenarios reales tanto interiores como exteriores y con diferente iluminación, generando una base de datos, inexistente hasta ahora para esta combinación de sensores. Los resultados experimentales demuestran el buen funcionamiento y la robustez del método propuesto. Se consigue expandir el área del suelo detectado unas 10 veces en entornos interiores y unas 20 veces en entornos de exterior, consiguiendo una elevada precisión.</dc:description>
    <dc:identifier>http://zaguan.unizar.es/record/78373</dc:identifier>
    <dc:language>spa</dc:language>
    <dc:publisher>Universidad de Zaragoza; Departamento de Informática e Ingeniería de Sistemas; Área de Ingeniería de Sistemas y Automática</dc:publisher>
    <dc:relation>http://zaguan.unizar.es/record/78373/files/TAZ-TFM-2019-012.pdf</dc:relation>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
    <dc:subject>Máster Universitario en Ingeniería Biomédica</dc:subject>
    <dc:title>Sistema de visión omnidireccional y de profundidad para guiado de discapacitados visuales</dc:title>
    <dc:type>TAZ-TFM</dc:type>
    <dc:title xml:lang="en">Omnidirectional and depth vision system for visual impaired guidance</dc:title>
</oai_dc:dc>
