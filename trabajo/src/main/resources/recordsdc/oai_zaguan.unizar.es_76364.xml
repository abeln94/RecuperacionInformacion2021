<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/">
    <dc:contributor>Murillo Arnal, Ana Cristina</dc:contributor>
    <dc:creator>Barbed Pérez, Óscar León</dc:creator>
    <dc:date>2018</dc:date>
    <dc:description>Un UAV (Unmanned Aerial Vehicle) o dron es un tipo de robot aéreo inicialmente creado con fines militares, pero que en la actualidad está siendo introducido como apoyo en muchas tareas de reconocimiento y rescate. Sus características lo hacen capaz de maniobrar en situaciones donde a un humano le resultarían complicadas. Sin embargo, su pilotaje tiene la desventaja de que el piloto habitualmente es incapaz de realizar otras tareas mientras controla el robot, pues el control remoto requiere el uso de ambas manos constantemente. En este trabajo se propone una solución a este problema a través de un reconocedor visual de gestos: un sistema capaz de procesar las imágenes captadas por una cámara y determinar la dirección en la que el piloto desea que avance el robot. Para ello, se hace uso de técnicas de deep learning, en concreto Convolutional Neural Networks o CNNs, por su demostrada eficacia en los últimos años en el campo del reconocimiento visual automático. El reconocimiento de gestos tiene dos fases principales: -Detección de personas. Fase en la que el sistema detecta si hay personas en la imagen y dónde se encuentran. Para esta fase se proponen dos alternativas: mediante segmentación semántica o mediante estimación de la postura. Ambos problemas han sido abordados haciendo uso de técnicas recientes basadas en \textit{deep learning}. -Clasificación del gesto. Una vez detectada la persona, esta fase coge esa información y determina qué gesto está realizando esa persona. En esta fase se proponen muchas alternativas para cada una de las opciones de la fase anterior, basadas en distintas técnicas de clasificación. En concreto se han estudiado Support Vector Machines o SVMs y CNNs. Este trabajo realiza una evaluación exhaustiva de las distintas alternativas para decidir cuál es la mejor arquitectura para el sistema final. Para esta evaluación se ha recopilado un nuevo conjunto de datos de evaluación más completo que los existentes en este ámbito. Además se ha implementado un prototipo funcional integrando las mejores alternativas de este estudio. El prototipo desarrollado funciona en tiempo real con una cámara RGB. El reconocedor está conectado con un módulo de ROS (Robot Operating System) que se encarga de gestionar la comunicación bien con un simulador de drones como con un dron real. Este sistema es evaluado en pruebas de integración, y comparado con un prototipo previo existente en el grupo de investigación que fue creado con objetivos similares, aunque con un enfoque más heurístico. Los resultados obtenidos muestran cómo el nuevo sistema obtiene resultados más robustos que el sistema anterior. Por lo tanto, el sistema desarrollado en este trabajo cumple las expectativas de no sólo reconocer los gestos con más precisión media que el prototipo previo, sino que lo hace de una manera más flexible a cambios y cómoda en su uso. Todo el código relacionado con el prototipo desarrollado está disponible en el repositorio del grupo de investigación: https://github.com/anacmurillo/unizar_interactive_robotics</dc:description>
    <dc:identifier>http://zaguan.unizar.es/record/76364</dc:identifier>
    <dc:language>spa</dc:language>
    <dc:publisher>Universidad de Zaragoza; Departamento de Informática e Ingeniería de Sistemas; Área de CC. de la Computación e Inteligencia Artificial</dc:publisher>
    <dc:relation>http://zaguan.unizar.es/record/76364/files/TAZ-TFG-2018-4638.pdf</dc:relation>
    <dc:rights>http://creativecommons.org/licenses/by-nc-sa/3.0/</dc:rights>
    <dc:subject>Graduado en Ingeniería Informática</dc:subject>
    <dc:title>Guiado de drones basado en reconocimiento de gestos con técnicas de Deep Learning</dc:title>
    <dc:type>TAZ-TFG</dc:type>
    <dc:title xml:lang="en">Drone guidance based on gesture recognition with Deep Learning</dc:title>
</oai_dc:dc>
